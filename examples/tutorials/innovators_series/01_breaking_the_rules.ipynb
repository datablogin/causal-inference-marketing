{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking the Rules: When Traditional RCTs Aren't Possible\n",
    "\n",
    "> *\"Rules for thee, but not for me\"* - When randomized controlled trials are impossible, impractical, or unethical, innovators find another way.\n",
    "\n",
    "## The Revolutionary Mindset\n",
    "\n",
    "Traditional statisticians might tell you that without randomization, you cannot establish causality. **They're wrong.** This tutorial will show you how to break free from the constraints of traditional experimental design and discover causal relationships in the wild.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "- Why randomization isn't always the answer\n",
    "- Creative approaches to causal identification\n",
    "- Real-world case studies of \"impossible\" causal inference\n",
    "- How to think like a causal detective\n",
    "- Methods that work when RCTs fail\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "Imagine you're trying to answer these questions:\n",
    "- Does a new city policy reduce crime? (Can't randomize cities)\n",
    "- Do violent video games cause aggression? (Unethical to expose children)\n",
    "- Does education improve lifetime earnings? (Can't deny education randomly)\n",
    "- Does smoking cause cancer? (Unethical to assign smoking)\n",
    "\n",
    "Traditional RCT advocates would say these questions are unanswerable with certainty. **Innovators prove them wrong.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: The Tools of Innovation\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../../\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, os.path.join(project_root, \"libs\"))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Import our causal inference arsenal\n",
    "from causal_inference.core.base import CovariateData, OutcomeData, TreatmentData\n",
    "from causal_inference.estimators.difference_in_differences import (\n",
    "    DifferenceInDifferencesEstimator,\n",
    ")\n",
    "from causal_inference.estimators.iv import IVEstimator\n",
    "from causal_inference.estimators.regression_discontinuity import RDDEstimator\n",
    "\n",
    "# Set the stage for innovation\n",
    "np.random.seed(42)\n",
    "plt.style.use(\"default\")  # Use default style instead of deprecated seaborn style\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üöÄ Ready to break the rules and discover causal truth!\")\n",
    "print(\"üí° Remember: Innovation begins where conventional wisdom ends.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Instrumental Variables - Finding Nature's Experiments\n",
    "\n",
    "**The Big Idea**: When you can't randomize the treatment, find something else that randomly affects treatment assignment but only affects the outcome through treatment.\n",
    "\n",
    "### Real-World Case Study: Education and Earnings\n",
    "\n",
    "*Question*: Does education causally increase earnings?\n",
    "*Problem*: We can't randomly assign education levels to people\n",
    "*Innovation*: Use distance to college as an instrumental variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Study 1: Education and Earnings - The Impossible Made Possible\n",
    "\n",
    "\n",
    "def generate_education_earnings_data(n=1000):\n",
    "    \"\"\"\n",
    "    Generate synthetic data mimicking the education-earnings relationship\n",
    "    with distance to college as an instrumental variable\n",
    "    \"\"\"\n",
    "    # Background characteristics (confounders)\n",
    "    family_income = np.random.normal(\n",
    "        50000, 20000, n\n",
    "    )  # Family income affects both education and earnings\n",
    "    ability = np.random.normal(\n",
    "        100, 15, n\n",
    "    )  # Ability affects both education and earnings\n",
    "\n",
    "    # Instrumental variable: Distance to nearest college (randomly distributed by geography)\n",
    "    distance_to_college = np.random.exponential(20, n)  # Miles\n",
    "\n",
    "    # First stage: Distance affects education (closer = more education)\n",
    "    # Education also depends on family income and ability\n",
    "    education_propensity = (\n",
    "        12  # Base education\n",
    "        + -0.05 * distance_to_college  # Distance reduces education\n",
    "        + 0.00008 * family_income  # Family income increases education\n",
    "        + 0.05 * ability  # Ability increases education\n",
    "        + np.random.normal(0, 2, n)\n",
    "    )  # Random variation\n",
    "\n",
    "    years_education = np.clip(education_propensity, 8, 20)  # 8-20 years of education\n",
    "\n",
    "    # Second stage: Education affects earnings\n",
    "    # Earnings also depend on ability and family background\n",
    "    true_education_effect = 3000  # True causal effect: $3000 per year of education\n",
    "\n",
    "    annual_earnings = (\n",
    "        20000  # Base earnings\n",
    "        + true_education_effect * years_education  # True causal effect\n",
    "        + 0.3 * family_income  # Family background effect\n",
    "        + 800 * ability  # Ability effect\n",
    "        + np.random.normal(0, 10000, n)\n",
    "    )  # Random variation\n",
    "\n",
    "    annual_earnings = np.clip(annual_earnings, 15000, 200000)  # Realistic range\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"years_education\": years_education,\n",
    "            \"annual_earnings\": annual_earnings,\n",
    "            \"distance_to_college\": distance_to_college,\n",
    "            \"family_income\": family_income,\n",
    "            \"ability\": ability,\n",
    "        }\n",
    "    ), true_education_effect\n",
    "\n",
    "\n",
    "# Generate the data\n",
    "education_data, true_effect = generate_education_earnings_data(1000)\n",
    "\n",
    "print(\"üìä Education and Earnings Dataset Generated\")\n",
    "print(f\"True causal effect of education: ${true_effect:,} per year\")\n",
    "print(\"\\nData preview:\")\n",
    "print(education_data.head())\n",
    "\n",
    "# Visualize the relationship\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Raw correlation (biased)\n",
    "axes[0, 0].scatter(\n",
    "    education_data[\"years_education\"], education_data[\"annual_earnings\"], alpha=0.6\n",
    ")\n",
    "correlation = np.corrcoef(\n",
    "    education_data[\"years_education\"], education_data[\"annual_earnings\"]\n",
    ")[0, 1]\n",
    "axes[0, 0].set_title(\n",
    "    f\"Raw Correlation: Education vs Earnings\\nr = {correlation:.3f} (BIASED!)\"\n",
    ")\n",
    "axes[0, 0].set_xlabel(\"Years of Education\")\n",
    "axes[0, 0].set_ylabel(\"Annual Earnings ($)\")\n",
    "\n",
    "# First stage: Distance to college affects education\n",
    "axes[0, 1].scatter(\n",
    "    education_data[\"distance_to_college\"], education_data[\"years_education\"], alpha=0.6\n",
    ")\n",
    "first_stage_corr = np.corrcoef(\n",
    "    education_data[\"distance_to_college\"], education_data[\"years_education\"]\n",
    ")[0, 1]\n",
    "axes[0, 1].set_title(\n",
    "    f\"First Stage: Distance vs Education\\nr = {first_stage_corr:.3f} (Good!)\"\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"Distance to College (miles)\")\n",
    "axes[0, 1].set_ylabel(\"Years of Education\")\n",
    "\n",
    "# Reduced form: Distance to college affects earnings (only through education)\n",
    "axes[1, 0].scatter(\n",
    "    education_data[\"distance_to_college\"], education_data[\"annual_earnings\"], alpha=0.6\n",
    ")\n",
    "reduced_form_corr = np.corrcoef(\n",
    "    education_data[\"distance_to_college\"], education_data[\"annual_earnings\"]\n",
    ")[0, 1]\n",
    "axes[1, 0].set_title(f\"Reduced Form: Distance vs Earnings\\nr = {reduced_form_corr:.3f}\")\n",
    "axes[1, 0].set_xlabel(\"Distance to College (miles)\")\n",
    "axes[1, 0].set_ylabel(\"Annual Earnings ($)\")\n",
    "\n",
    "# Distribution of the instrument\n",
    "axes[1, 1].hist(education_data[\"distance_to_college\"], bins=30, alpha=0.7)\n",
    "axes[1, 1].set_title(\"Distribution of Instrumental Variable\")\n",
    "axes[1, 1].set_xlabel(\"Distance to College (miles)\")\n",
    "axes[1, 1].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç What we see:\")\n",
    "print(\n",
    "    f\"‚Ä¢ Raw correlation suggests ${correlation * 10000:.0f} per year of education (BIASED!)\"\n",
    ")\n",
    "print(f\"‚Ä¢ First stage shows distance affects education: {first_stage_corr:.3f}\")\n",
    "print(f\"‚Ä¢ Reduced form shows distance affects earnings: {reduced_form_corr:.3f}\")\n",
    "print(f\"‚Ä¢ True effect: ${true_effect:,} per year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Instrumental Variables - Breaking the Randomization Rule\n",
    "\n",
    "# Prepare data for IV estimation\n",
    "treatment = TreatmentData(\n",
    "    values=education_data[\"years_education\"],\n",
    "    name=\"years_education\",\n",
    "    treatment_type=\"continuous\",\n",
    ")\n",
    "\n",
    "outcome = OutcomeData(\n",
    "    values=education_data[\"annual_earnings\"],\n",
    "    name=\"annual_earnings\",\n",
    "    outcome_type=\"continuous\",\n",
    ")\n",
    "\n",
    "# Instrumental variable: Distance to college\n",
    "instrument = education_data[[\"distance_to_college\"]]\n",
    "\n",
    "# Control variables\n",
    "covariates = CovariateData(\n",
    "    values=education_data[[\"family_income\", \"ability\"]],\n",
    "    names=[\"family_income\", \"ability\"],\n",
    ")\n",
    "\n",
    "print(\"üéØ Using Instrumental Variables to Identify Causal Effects\")\n",
    "print(\"üìê Instrument: Distance to college\")\n",
    "print(\"üéì Treatment: Years of education\")\n",
    "print(\"üí∞ Outcome: Annual earnings\")\n",
    "\n",
    "# Check IV assumptions using available diagnostics\n",
    "print(\"\\nüîç Checking IV Assumptions...\")\n",
    "\n",
    "# Manual check of first stage strength\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# First stage regression\n",
    "X_first_stage = education_data[[\"distance_to_college\", \"family_income\", \"ability\"]]\n",
    "y_first_stage = education_data[\"years_education\"]\n",
    "first_stage = LinearRegression().fit(X_first_stage, y_first_stage)\n",
    "\n",
    "# Calculate F-statistic for instrument relevance\n",
    "instrument_coef = first_stage.coef_[0]  # Coefficient on distance_to_college\n",
    "y_pred = first_stage.predict(X_first_stage)\n",
    "residuals = y_first_stage - y_pred\n",
    "mse = np.mean(residuals**2)\n",
    "se_instrument = np.sqrt(mse * np.linalg.inv(X_first_stage.T @ X_first_stage)[0, 0])\n",
    "t_stat = instrument_coef / se_instrument\n",
    "f_stat = t_stat**2\n",
    "\n",
    "print(f\"‚úÖ Relevance (First stage F-stat > 10): {f_stat:.2f}\")\n",
    "if f_stat > 10:\n",
    "    print(\"   üéØ Strong instrument - passes relevance test!\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Weak instrument - may have bias issues\")\n",
    "\n",
    "print(\"‚ö†Ô∏è  Exogeneity (untestable): Assume distance is random\")\n",
    "print(\"üéØ Exclusion (untestable): Distance only affects earnings through education\")\n",
    "\n",
    "# Estimate causal effect using IV\n",
    "iv_estimator = IVEstimator(\n",
    "    first_stage_model=\"linear\", second_stage_model=\"linear\", bootstrap_samples=100\n",
    ")\n",
    "\n",
    "iv_estimator.fit(treatment, outcome, covariates, instrument)\n",
    "iv_effect = iv_estimator.estimate_ate()\n",
    "\n",
    "print(\"\\nüéâ BREAKTHROUGH RESULTS:\")\n",
    "print(f\"üí° IV Estimate: ${iv_effect.ate:,.0f} per year of education\")\n",
    "print(f\"üéØ True Effect: ${true_effect:,} per year\")\n",
    "print(\n",
    "    f\"üìä 95% CI: [${iv_effect.confidence_interval[0]:,.0f}, ${iv_effect.confidence_interval[1]:,.0f}]\"\n",
    ")\n",
    "print(f\"‚ú® Bias from raw correlation: ${abs((correlation * 10000) - true_effect):,.0f}\")\n",
    "\n",
    "# Compare with naive approaches\n",
    "naive_ols = np.polyfit(\n",
    "    education_data[\"years_education\"], education_data[\"annual_earnings\"], 1\n",
    ")[0]\n",
    "\n",
    "print(\"\\nü§î Comparison of Methods:\")\n",
    "print(f\"üìà Naive OLS (biased): ${naive_ols:,.0f}\")\n",
    "print(f\"üéØ IV Estimate (unbiased): ${iv_effect.ate:,.0f}\")\n",
    "print(f\"‚úÖ True Effect: ${true_effect:,}\")\n",
    "\n",
    "bias_reduction = abs(naive_ols - true_effect) - abs(iv_effect.ate - true_effect)\n",
    "print(f\"üöÄ Bias reduction: ${bias_reduction:,.0f}\")\n",
    "\n",
    "if abs(iv_effect.ate - true_effect) < abs(naive_ols - true_effect):\n",
    "    print(\"\\nüèÜ VICTORY! IV estimation recovered the true causal effect!\")\n",
    "    print(\"üéØ This is why we break the rules - to find the truth!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Even IV has limitations, but it's still better than naive correlation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Regression Discontinuity - Exploiting Arbitrary Cutoffs\n",
    "\n",
    "**The Innovation**: When treatment is assigned based on an arbitrary threshold, we can treat observations just above and below the cutoff as randomly assigned.\n",
    "\n",
    "### Real-World Case Study: Financial Aid and College Success\n",
    "\n",
    "*Question*: Does financial aid improve college graduation rates?\n",
    "*Problem*: Students who get aid are different from those who don't\n",
    "*Innovation*: Use the arbitrary GPA cutoff for aid eligibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Study 2: Financial Aid and College Success - The Cutoff Revolution\n",
    "\n",
    "\n",
    "def generate_financial_aid_data(n=800):\n",
    "    \"\"\"\n",
    "    Generate data for financial aid and college graduation\n",
    "    with a sharp cutoff at GPA = 3.0 for aid eligibility\n",
    "    \"\"\"\n",
    "    # Running variable: High school GPA (centered around cutoff)\n",
    "    gpa_cutoff = 3.0\n",
    "    high_school_gpa = np.random.normal(3.0, 0.5, n)\n",
    "    high_school_gpa = np.clip(high_school_gpa, 1.5, 4.0)  # Realistic range\n",
    "\n",
    "    # Sharp discontinuity: Aid assigned based on GPA >= 3.0\n",
    "    receives_aid = (high_school_gpa >= gpa_cutoff).astype(int)\n",
    "\n",
    "    # Background characteristics\n",
    "    family_income = np.random.normal(40000, 15000, n)\n",
    "    parent_college = np.random.binomial(1, 0.3, n)\n",
    "\n",
    "    # Smooth relationship: GPA predicts success\n",
    "    base_graduation_prob = 0.3 + 0.4 * (high_school_gpa - 1.5) / (4.0 - 1.5)\n",
    "\n",
    "    # True causal effect of aid (the discontinuous jump)\n",
    "    true_aid_effect = 0.25  # 25 percentage point increase\n",
    "\n",
    "    # Final graduation probability\n",
    "    graduation_prob = (\n",
    "        base_graduation_prob\n",
    "        + true_aid_effect * receives_aid\n",
    "        + 0.1 * parent_college  # Parent education effect\n",
    "        + np.random.normal(0, 0.1, n)\n",
    "    )  # Random noise\n",
    "\n",
    "    graduation_prob = np.clip(graduation_prob, 0.05, 0.95)\n",
    "    graduated = np.random.binomial(1, graduation_prob, n)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"high_school_gpa\": high_school_gpa,\n",
    "            \"receives_aid\": receives_aid,\n",
    "            \"graduated\": graduated,\n",
    "            \"family_income\": family_income,\n",
    "            \"parent_college\": parent_college,\n",
    "            \"distance_from_cutoff\": high_school_gpa - gpa_cutoff,\n",
    "        }\n",
    "    ), true_aid_effect\n",
    "\n",
    "\n",
    "# Generate the data\n",
    "aid_data, true_aid_effect = generate_financial_aid_data(800)\n",
    "\n",
    "print(\"üéì Financial Aid and College Success Dataset Generated\")\n",
    "print(f\"True causal effect of aid: {true_aid_effect:.1%} increase in graduation rate\")\n",
    "print(\"Aid cutoff: GPA ‚â• 3.0\")\n",
    "print(\"\\nData preview:\")\n",
    "print(aid_data.head())\n",
    "\n",
    "# Visualize the discontinuity\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Treatment assignment (sharp discontinuity)\n",
    "gpa_bins = np.linspace(\n",
    "    aid_data[\"high_school_gpa\"].min(), aid_data[\"high_school_gpa\"].max(), 20\n",
    ")\n",
    "binned_data = (\n",
    "    aid_data.groupby(pd.cut(aid_data[\"high_school_gpa\"], gpa_bins))\n",
    "    .agg({\"receives_aid\": \"mean\", \"graduated\": \"mean\", \"high_school_gpa\": \"mean\"})\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "axes[0, 0].scatter(binned_data[\"high_school_gpa\"], binned_data[\"receives_aid\"], s=50)\n",
    "axes[0, 0].axvline(x=3.0, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Aid Cutoff\")\n",
    "axes[0, 0].set_title(\"Treatment Assignment: Sharp Discontinuity at GPA = 3.0\")\n",
    "axes[0, 0].set_xlabel(\"High School GPA\")\n",
    "axes[0, 0].set_ylabel(\"Probability of Receiving Aid\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_ylim(-0.1, 1.1)\n",
    "\n",
    "# Outcome discontinuity (the causal effect!)\n",
    "axes[0, 1].scatter(\n",
    "    binned_data[\"high_school_gpa\"], binned_data[\"graduated\"], s=50, color=\"orange\"\n",
    ")\n",
    "axes[0, 1].axvline(x=3.0, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Aid Cutoff\")\n",
    "axes[0, 1].set_title(\"Outcome: Graduation Rate Jumps at Cutoff!\")\n",
    "axes[0, 1].set_xlabel(\"High School GPA\")\n",
    "axes[0, 1].set_ylabel(\"Graduation Rate\")\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Raw data scatter\n",
    "colors = [\"red\" if aid == 0 else \"blue\" for aid in aid_data[\"receives_aid\"]]\n",
    "axes[1, 0].scatter(\n",
    "    aid_data[\"high_school_gpa\"], aid_data[\"graduated\"], alpha=0.6, c=colors, s=20\n",
    ")\n",
    "axes[1, 0].axvline(x=3.0, color=\"black\", linestyle=\"-\", alpha=0.8, linewidth=2)\n",
    "axes[1, 0].set_title(\"Raw Data: Red=No Aid, Blue=Aid\")\n",
    "axes[1, 0].set_xlabel(\"High School GPA\")\n",
    "axes[1, 0].set_ylabel(\"Graduated (0/1)\")\n",
    "\n",
    "# Histogram of running variable\n",
    "axes[1, 1].hist(aid_data[\"high_school_gpa\"], bins=30, alpha=0.7, edgecolor=\"black\")\n",
    "axes[1, 1].axvline(x=3.0, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Cutoff\")\n",
    "axes[1, 1].set_title(\"Distribution of Running Variable (GPA)\")\n",
    "axes[1, 1].set_xlabel(\"High School GPA\")\n",
    "axes[1, 1].set_ylabel(\"Frequency\")\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check if discontinuity is visible\n",
    "left_of_cutoff = aid_data[aid_data[\"high_school_gpa\"].between(2.9, 3.0)][\n",
    "    \"graduated\"\n",
    "].mean()\n",
    "right_of_cutoff = aid_data[aid_data[\"high_school_gpa\"].between(3.0, 3.1)][\n",
    "    \"graduated\"\n",
    "].mean()\n",
    "observed_jump = right_of_cutoff - left_of_cutoff\n",
    "\n",
    "print(\"\\nüîç Visual Evidence of Causal Effect:\")\n",
    "print(f\"üìâ Graduation rate just left of cutoff (2.9-3.0): {left_of_cutoff:.1%}\")\n",
    "print(f\"üìà Graduation rate just right of cutoff (3.0-3.1): {right_of_cutoff:.1%}\")\n",
    "print(f\"‚ö° Observed jump at cutoff: {observed_jump:.1%}\")\n",
    "print(f\"üéØ True causal effect: {true_aid_effect:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Regression Discontinuity Design - Exploiting Arbitrary Rules\n",
    "\n",
    "# Prepare data for RDD estimation\n",
    "treatment_rdd = TreatmentData(\n",
    "    values=aid_data[\"receives_aid\"], name=\"receives_aid\", treatment_type=\"binary\"\n",
    ")\n",
    "\n",
    "outcome_rdd = OutcomeData(\n",
    "    values=aid_data[\"graduated\"], name=\"graduated\", outcome_type=\"binary\"\n",
    ")\n",
    "\n",
    "# Running variable and cutoff\n",
    "running_variable = aid_data[\"high_school_gpa\"]\n",
    "cutoff = 3.0\n",
    "\n",
    "# Control variables (optional in RDD)\n",
    "covariates_rdd = CovariateData(\n",
    "    values=aid_data[[\"family_income\", \"parent_college\"]],\n",
    "    names=[\"family_income\", \"parent_college\"],\n",
    ")\n",
    "\n",
    "print(\"üìè Using Regression Discontinuity Design\")\n",
    "print(\"üéØ Running variable: High school GPA\")\n",
    "print(\"‚úÇÔ∏è Cutoff: 3.0 GPA\")\n",
    "print(\"üéì Treatment: Financial aid\")\n",
    "print(\"üìä Outcome: College graduation\")\n",
    "\n",
    "# Estimate causal effect using RDD\n",
    "rdd_estimator = RDDEstimator(\n",
    "    cutoff=cutoff,\n",
    "    kernel=\"triangular\",\n",
    "    bandwidth_method=\"optimal\",\n",
    "    bootstrap_samples=100,\n",
    ")\n",
    "\n",
    "print(\"\\nüîß Fitting RDD model...\")\n",
    "rdd_estimator.fit(treatment_rdd, outcome_rdd, running_variable, covariates_rdd)\n",
    "rdd_effect = rdd_estimator.estimate_ate()\n",
    "\n",
    "print(\"\\nüéâ REGRESSION DISCONTINUITY RESULTS:\")\n",
    "print(f\"üí° RDD Estimate: {rdd_effect.ate:.1%} increase in graduation rate\")\n",
    "print(f\"üéØ True Effect: {true_aid_effect:.1%}\")\n",
    "print(\n",
    "    f\"üìä 95% CI: [{rdd_effect.confidence_interval[0]:.1%}, {rdd_effect.confidence_interval[1]:.1%}]\"\n",
    ")\n",
    "print(f\"üéØ Effect is significant: {rdd_effect.is_significant}\")\n",
    "\n",
    "# Compare with naive comparison\n",
    "naive_effect = (\n",
    "    aid_data[aid_data[\"receives_aid\"] == 1][\"graduated\"].mean()\n",
    "    - aid_data[aid_data[\"receives_aid\"] == 0][\"graduated\"].mean()\n",
    ")\n",
    "\n",
    "print(\"\\nü§î Comparison of Methods:\")\n",
    "print(f\"üìà Naive comparison (biased): {naive_effect:.1%}\")\n",
    "print(f\"üìè RDD estimate (unbiased): {rdd_effect.ate:.1%}\")\n",
    "print(f\"‚úÖ True effect: {true_aid_effect:.1%}\")\n",
    "\n",
    "if abs(rdd_effect.ate - true_aid_effect) < abs(naive_effect - true_aid_effect):\n",
    "    print(\"\\nüèÜ ANOTHER VICTORY! RDD revealed the true causal effect!\")\n",
    "    print(\"üî• By exploiting an arbitrary cutoff, we discovered causality!\")\n",
    "    print(\"üí° This is the power of thinking outside the RCT box!\")\n",
    "\n",
    "# Visualize the RDD results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Plot the fitted discontinuity\n",
    "gpa_range = np.linspace(\n",
    "    aid_data[\"high_school_gpa\"].min(), aid_data[\"high_school_gpa\"].max(), 100\n",
    ")\n",
    "bandwidth = getattr(\n",
    "    rdd_estimator, \"bandwidth_\", 0.5\n",
    ")  # Use estimated or default bandwidth\n",
    "\n",
    "# Create binned averages for visualization\n",
    "n_bins = 20\n",
    "gpa_bins = np.linspace(\n",
    "    aid_data[\"high_school_gpa\"].min(), aid_data[\"high_school_gpa\"].max(), n_bins\n",
    ")\n",
    "binned_means = []\n",
    "binned_gpa = []\n",
    "\n",
    "for i in range(len(gpa_bins) - 1):\n",
    "    mask = (aid_data[\"high_school_gpa\"] >= gpa_bins[i]) & (\n",
    "        aid_data[\"high_school_gpa\"] < gpa_bins[i + 1]\n",
    "    )\n",
    "    if mask.sum() > 0:\n",
    "        binned_means.append(aid_data[mask][\"graduated\"].mean())\n",
    "        binned_gpa.append(aid_data[mask][\"high_school_gpa\"].mean())\n",
    "\n",
    "# Plot binned data\n",
    "ax.scatter(binned_gpa, binned_means, s=60, alpha=0.8, zorder=3)\n",
    "\n",
    "# Highlight the discontinuity\n",
    "ax.axvline(\n",
    "    x=cutoff,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.7,\n",
    "    linewidth=2,\n",
    "    label=f\"Cutoff (GPA = {cutoff})\",\n",
    ")\n",
    "\n",
    "# Add effect annotation\n",
    "ax.annotate(\n",
    "    f\"Causal Effect: {rdd_effect.ate:.1%}\",\n",
    "    xy=(cutoff + 0.05, 0.5),\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    "    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"High School GPA (Running Variable)\", fontsize=12)\n",
    "ax.set_ylabel(\"Graduation Rate\", fontsize=12)\n",
    "ax.set_title(\n",
    "    \"Regression Discontinuity: Financial Aid Effect on Graduation\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Key Insight: Students just above vs just below the GPA cutoff\")\n",
    "print(\"   are essentially identical except for aid - this is nature's experiment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Difference-in-Differences - Using Time as Your Friend\n",
    "\n",
    "**The Revolution**: When treatment happens to some groups but not others at a specific time, we can use the before-after, treatment-control comparison to identify causal effects.\n",
    "\n",
    "### Real-World Case Study: Minimum Wage and Employment\n",
    "\n",
    "*Question*: Does raising minimum wage reduce employment?\n",
    "*Problem*: States that raise wages are different from those that don't\n",
    "*Innovation*: Compare changes in employment before and after wage increases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Study 3: Minimum Wage Policy - Time Reveals Truth\n",
    "\n",
    "\n",
    "def generate_minimum_wage_data():\n",
    "    \"\"\"\n",
    "    Generate synthetic minimum wage and employment data\n",
    "    Treatment group (New Jersey) raises wage in 1994\n",
    "    Control group (Pennsylvania) does not\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "\n",
    "    # Time periods\n",
    "    years = [1993, 1994, 1995, 1996]  # Pre and post treatment\n",
    "    states = [\"New Jersey (Treatment)\", \"Pennsylvania (Control)\"]\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # True effect: Minimum wage increase has NO effect on employment (contrary to theory!)\n",
    "    true_effect = 0.0  # Revolutionary finding!\n",
    "\n",
    "    for state in states:\n",
    "        is_treatment = \"Treatment\" in state\n",
    "\n",
    "        for year in years:\n",
    "            # Treatment occurs in 1994 for New Jersey\n",
    "            post_treatment = year >= 1994\n",
    "            treated = is_treatment and post_treatment\n",
    "\n",
    "            # Base employment rate with state-specific differences\n",
    "            if is_treatment:\n",
    "                base_employment = 0.72  # NJ baseline slightly higher\n",
    "            else:\n",
    "                base_employment = 0.70  # PA baseline\n",
    "\n",
    "            # Common time trend (economic recovery)\n",
    "            time_trend = 0.01 * (year - 1993)  # 1% per year improvement\n",
    "\n",
    "            # Treatment effect (the key parameter!)\n",
    "            treatment_effect = true_effect if treated else 0.0\n",
    "\n",
    "            # Final employment rate\n",
    "            employment_rate = (\n",
    "                base_employment\n",
    "                + time_trend\n",
    "                + treatment_effect\n",
    "                + np.random.normal(0, 0.02)\n",
    "            )  # Noise\n",
    "\n",
    "            employment_rate = np.clip(employment_rate, 0.5, 0.95)\n",
    "\n",
    "            # Minimum wage\n",
    "            if is_treatment and post_treatment:\n",
    "                min_wage = 5.05  # Raised wage\n",
    "            elif is_treatment:\n",
    "                min_wage = 4.25  # Pre-treatment\n",
    "            else:\n",
    "                min_wage = 4.25  # Control always at federal minimum\n",
    "\n",
    "            data.append(\n",
    "                {\n",
    "                    \"state\": state,\n",
    "                    \"year\": year,\n",
    "                    \"is_treatment_state\": is_treatment,\n",
    "                    \"post_treatment\": post_treatment,\n",
    "                    \"treated\": treated,\n",
    "                    \"employment_rate\": employment_rate,\n",
    "                    \"min_wage\": min_wage,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(data), true_effect\n",
    "\n",
    "\n",
    "# Generate the data\n",
    "wage_data, true_wage_effect = generate_minimum_wage_data()\n",
    "\n",
    "print(\"üíº Minimum Wage and Employment Dataset Generated\")\n",
    "print(\n",
    "    f\"True effect of minimum wage increase: {true_wage_effect:.1%} change in employment\"\n",
    ")\n",
    "print(\"Treatment: New Jersey raises minimum wage in 1994\")\n",
    "print(\"Control: Pennsylvania keeps wage constant\")\n",
    "print(\"\\nData preview:\")\n",
    "print(wage_data)\n",
    "\n",
    "# Visualize the difference-in-differences setup\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Employment trends\n",
    "for state in wage_data[\"state\"].unique():\n",
    "    state_data = wage_data[wage_data[\"state\"] == state]\n",
    "    color = \"blue\" if \"Treatment\" in state else \"red\"\n",
    "    linestyle = \"-\" if \"Treatment\" in state else \"--\"\n",
    "    axes[0].plot(\n",
    "        state_data[\"year\"],\n",
    "        state_data[\"employment_rate\"],\n",
    "        marker=\"o\",\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "        label=state,\n",
    "    )\n",
    "\n",
    "# Mark treatment period\n",
    "axes[0].axvline(\n",
    "    x=1993.5, color=\"gray\", linestyle=\":\", alpha=0.7, label=\"Treatment Starts\"\n",
    ")\n",
    "axes[0].set_title(\n",
    "    \"Employment Trends: Treatment vs Control\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "axes[0].set_xlabel(\"Year\")\n",
    "axes[0].set_ylabel(\"Employment Rate\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Minimum wage levels\n",
    "for state in wage_data[\"state\"].unique():\n",
    "    state_data = wage_data[wage_data[\"state\"] == state]\n",
    "    color = \"blue\" if \"Treatment\" in state else \"red\"\n",
    "    linestyle = \"-\" if \"Treatment\" in state else \"--\"\n",
    "    axes[1].plot(\n",
    "        state_data[\"year\"],\n",
    "        state_data[\"min_wage\"],\n",
    "        marker=\"s\",\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "        label=state,\n",
    "    )\n",
    "\n",
    "axes[1].axvline(\n",
    "    x=1993.5, color=\"gray\", linestyle=\":\", alpha=0.7, label=\"Treatment Starts\"\n",
    ")\n",
    "axes[1].set_title(\"Minimum Wage Levels\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"Year\")\n",
    "axes[1].set_ylabel(\"Minimum Wage ($)\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate components of DiD\n",
    "pre_treatment = wage_data[wage_data[\"post_treatment\"] == False]\n",
    "post_treatment = wage_data[wage_data[\"post_treatment\"] == True]\n",
    "\n",
    "# Before-after difference for treatment group\n",
    "nj_pre = pre_treatment[pre_treatment[\"is_treatment_state\"]][\"employment_rate\"].mean()\n",
    "nj_post = post_treatment[post_treatment[\"is_treatment_state\"]][\"employment_rate\"].mean()\n",
    "nj_change = nj_post - nj_pre\n",
    "\n",
    "# Before-after difference for control group\n",
    "pa_pre = pre_treatment[~pre_treatment[\"is_treatment_state\"]][\"employment_rate\"].mean()\n",
    "pa_post = post_treatment[~post_treatment[\"is_treatment_state\"]][\n",
    "    \"employment_rate\"\n",
    "].mean()\n",
    "pa_change = pa_post - pa_pre\n",
    "\n",
    "# Difference-in-differences\n",
    "did_effect = nj_change - pa_change\n",
    "\n",
    "print(\"\\nüìä Difference-in-Differences Components:\")\n",
    "print(f\"üîµ NJ (Treatment): {nj_pre:.1%} ‚Üí {nj_post:.1%} (Change: {nj_change:+.1%})\")\n",
    "print(f\"üî¥ PA (Control): {pa_pre:.1%} ‚Üí {pa_post:.1%} (Change: {pa_change:+.1%})\")\n",
    "print(f\"‚ö° Difference-in-Differences: {did_effect:+.1%}\")\n",
    "print(f\"üéØ True effect: {true_wage_effect:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Difference-in-Differences - Time Reveals Causality\n",
    "\n",
    "# Prepare data for DiD estimation\n",
    "treatment_did = TreatmentData(\n",
    "    values=wage_data[\"treated\"].astype(int), name=\"treated\", treatment_type=\"binary\"\n",
    ")\n",
    "\n",
    "outcome_did = OutcomeData(\n",
    "    values=wage_data[\"employment_rate\"],\n",
    "    name=\"employment_rate\",\n",
    "    outcome_type=\"continuous\",\n",
    ")\n",
    "\n",
    "# Group and time indicators\n",
    "group_indicator = wage_data[\"is_treatment_state\"].astype(int)\n",
    "time_indicator = wage_data[\"post_treatment\"].astype(int)\n",
    "\n",
    "print(\"‚è∞ Using Difference-in-Differences Design\")\n",
    "print(\"üèõÔ∏è Treatment Group: New Jersey (raised minimum wage)\")\n",
    "print(\"üèõÔ∏è Control Group: Pennsylvania (kept wage constant)\")\n",
    "print(\"üìÖ Treatment Time: 1994 onwards\")\n",
    "print(\"üíº Outcome: Employment rate\")\n",
    "\n",
    "# Estimate causal effect using DiD\n",
    "did_estimator = DifferenceInDifferencesEstimator(bootstrap_samples=100)\n",
    "\n",
    "print(\"\\nüîß Fitting DiD model...\")\n",
    "did_estimator.fit(\n",
    "    treatment=treatment_did,\n",
    "    outcome=outcome_did,\n",
    "    group_indicator=group_indicator,\n",
    "    time_indicator=time_indicator,\n",
    ")\n",
    "\n",
    "did_effect_result = did_estimator.estimate_ate()\n",
    "\n",
    "print(\"\\nüéâ DIFFERENCE-IN-DIFFERENCES RESULTS:\")\n",
    "print(f\"üí° DiD Estimate: {did_effect_result.ate:+.1%} change in employment\")\n",
    "print(f\"üéØ True Effect: {true_wage_effect:.1%}\")\n",
    "print(\n",
    "    f\"üìä 95% CI: [{did_effect_result.confidence_interval[0]:+.1%}, {did_effect_result.confidence_interval[1]:+.1%}]\"\n",
    ")\n",
    "print(f\"üéØ Effect is significant: {did_effect_result.is_significant}\")\n",
    "\n",
    "# Manual calculation for verification\n",
    "print(f\"\\nüßÆ Manual DiD Calculation: {did_effect:+.1%} (matches!)\")\n",
    "\n",
    "# Compare with naive approaches\n",
    "naive_before_after = nj_change\n",
    "naive_cross_section = (\n",
    "    post_treatment[post_treatment[\"is_treatment_state\"]][\"employment_rate\"].mean()\n",
    "    - post_treatment[~post_treatment[\"is_treatment_state\"]][\"employment_rate\"].mean()\n",
    ")\n",
    "\n",
    "print(\"\\nü§î Comparison of Methods:\")\n",
    "print(f\"üìà Naive before-after (biased): {naive_before_after:+.1%}\")\n",
    "print(f\"üìä Naive cross-section (biased): {naive_cross_section:+.1%}\")\n",
    "print(f\"‚è∞ DiD estimate (unbiased): {did_effect_result.ate:+.1%}\")\n",
    "print(f\"‚úÖ True effect: {true_wage_effect:.1%}\")\n",
    "\n",
    "print(\"\\nüß† Key Insights:\")\n",
    "print(f\"‚Ä¢ Before-after comparison is biased by time trends ({pa_change:+.1%})\")\n",
    "print(\"‚Ä¢ Cross-section comparison is biased by state differences\")\n",
    "print(\"‚Ä¢ DiD removes BOTH biases by using the control group!\")\n",
    "\n",
    "if abs(did_effect_result.ate - true_wage_effect) < 0.02:  # Within 2 percentage points\n",
    "    print(\"\\nüèÜ REVOLUTIONARY SUCCESS! DiD revealed the truth!\")\n",
    "    print(\"üî• Minimum wage increases don't hurt employment!\")\n",
    "    print(\"üí° This challenges conventional economic theory!\")\n",
    "    print(\"üåü By using time cleverly, we discovered causality!\")\n",
    "\n",
    "# Create DiD visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Calculate group means by period\n",
    "means = (\n",
    "    wage_data.groupby([\"is_treatment_state\", \"post_treatment\"])[\"employment_rate\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "# Plot the DiD\n",
    "periods = [\"Pre-Treatment\", \"Post-Treatment\"]\n",
    "treatment_means = [means.loc[True, False], means.loc[True, True]]\n",
    "control_means = [means.loc[False, False], means.loc[False, True]]\n",
    "\n",
    "ax.plot(\n",
    "    periods,\n",
    "    treatment_means,\n",
    "    \"o-\",\n",
    "    color=\"blue\",\n",
    "    linewidth=3,\n",
    "    markersize=10,\n",
    "    label=\"Treatment (New Jersey)\",\n",
    ")\n",
    "ax.plot(\n",
    "    periods,\n",
    "    control_means,\n",
    "    \"o--\",\n",
    "    color=\"red\",\n",
    "    linewidth=3,\n",
    "    markersize=10,\n",
    "    label=\"Control (Pennsylvania)\",\n",
    ")\n",
    "\n",
    "# Add effect annotation\n",
    "mid_treatment = np.mean(treatment_means)\n",
    "ax.annotate(\n",
    "    f\"DiD Effect: {did_effect_result.ate:+.1%}\",\n",
    "    xy=(1, treatment_means[1]),\n",
    "    xytext=(1.2, mid_treatment),\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    "    arrowprops=dict(arrowstyle=\"->\", color=\"black\", lw=1.5),\n",
    "    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.8),\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Employment Rate\", fontsize=12)\n",
    "ax.set_title(\n",
    "    \"Difference-in-Differences: Minimum Wage Effect\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ The Power of Innovation: By combining space AND time,\")\n",
    "print(\"   DiD eliminated confounding and revealed the true causal effect!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Revolutionary Mindset: Key Principles\n",
    "\n",
    "### 1. Question Everything\n",
    "- **Traditional thinking**: \"We need randomization for causality\"\n",
    "- **Revolutionary thinking**: \"Nature provides experiments everywhere\"\n",
    "\n",
    "### 2. Look for Natural Experiments\n",
    "- Geographic boundaries (states, countries)\n",
    "- Arbitrary cutoffs (GPA thresholds, age limits)\n",
    "- Policy changes (laws, regulations)\n",
    "- Random events (lotteries, weather)\n",
    "\n",
    "### 3. Exploit Institutional Rules\n",
    "- School assignment boundaries\n",
    "- Eligibility thresholds\n",
    "- Bureaucratic procedures\n",
    "- Historical accidents\n",
    "\n",
    "### 4. Think Like a Detective\n",
    "- What creates variation in treatment?\n",
    "- Is this variation \"as good as random\"?\n",
    "- What other factors could explain the outcome?\n",
    "- How can I rule out alternative explanations?\n",
    "\n",
    "## Challenge Exercise: Find Your Own Natural Experiment\n",
    "\n",
    "Think of a causal question in your field where randomization is impossible. Then:\n",
    "\n",
    "1. **Identify potential instruments** - What randomly affects your treatment?\n",
    "2. **Look for discontinuities** - Are there arbitrary cutoffs in your domain?\n",
    "3. **Find natural experiments** - What events create random variation?\n",
    "4. **Design your approach** - How would you exploit this variation?\n",
    "\n",
    "### Examples to Inspire You:\n",
    "\n",
    "- **Marketing**: Store opening decisions based on population thresholds\n",
    "- **Healthcare**: Hospital admission cutoffs based on bed availability  \n",
    "- **Education**: Classroom size limits creating random assignment\n",
    "- **Technology**: Server assignments based on user ID ranges\n",
    "- **Finance**: Credit decisions based on arbitrary score cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Challenge: Design a Natural Experiment\n",
    "\n",
    "print(\"üéØ CHALLENGE: Design Your Own Natural Experiment\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"Step 1: Choose a causal question where RCTs are impossible\")\n",
    "print(\"Examples:\")\n",
    "print(\"‚Ä¢ Does city size affect innovation rates?\")\n",
    "print(\"‚Ä¢ Do strict parents create more successful children?\")\n",
    "print(\"‚Ä¢ Does social media use cause depression?\")\n",
    "print(\"‚Ä¢ Do open offices increase productivity?\")\n",
    "print()\n",
    "print(\"Step 2: Identify your identification strategy\")\n",
    "print(\"Options:\")\n",
    "print(\"üéª Instrumental Variables: Find something that randomly affects treatment\")\n",
    "print(\"üìè Regression Discontinuity: Look for arbitrary cutoffs\")\n",
    "print(\"‚è∞ Difference-in-Differences: Find policy changes or events\")\n",
    "print()\n",
    "print(\"Step 3: Evaluate your approach\")\n",
    "print(\"Questions to ask:\")\n",
    "print(\"‚Ä¢ Is the variation truly random (or as good as random)?\")\n",
    "print(\"‚Ä¢ Can I defend the identifying assumptions?\")\n",
    "print(\"‚Ä¢ What are the potential threats to validity?\")\n",
    "print(\"‚Ä¢ How would I test my assumptions?\")\n",
    "\n",
    "# Example template for your own analysis\n",
    "my_research_question = \"\"\"\n",
    "YOUR RESEARCH QUESTION HERE:\n",
    "Example: Does working from home increase productivity?\n",
    "\n",
    "WHY RCTs ARE IMPOSSIBLE:\n",
    "Example: Companies can't randomly assign remote work policies\n",
    "\n",
    "MY IDENTIFICATION STRATEGY:\n",
    "Example: Use snow storms as an instrument - they force remote work randomly\n",
    "\n",
    "ASSUMPTIONS I NEED TO DEFEND:\n",
    "Example: Snow storms only affect productivity through remote work\n",
    "\n",
    "HOW I WOULD TEST THIS:\n",
    "Example: Check if snow affects productivity in jobs that can't be done remotely\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù Template for Your Analysis:\")\n",
    "print(my_research_question)\n",
    "\n",
    "print(\"\\nüåü Remember: Every 'impossible' causal question\")\n",
    "print(\"   is an opportunity for innovation!\")\n",
    "print(\"\\nüí° The best causal inference comes from creative thinking,\")\n",
    "print(\"   not just following textbook methods!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Breaking Free from Traditional Constraints\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **Randomization is not the only path to causality**\n",
    "   - Nature provides experiments everywhere\n",
    "   - Institutional rules create random variation\n",
    "   - Historical events offer natural experiments\n",
    "\n",
    "2. **Three powerful alternatives to RCTs**:\n",
    "   - **Instrumental Variables**: Exploit random factors that affect treatment\n",
    "   - **Regression Discontinuity**: Use arbitrary cutoffs as natural experiments\n",
    "   - **Difference-in-Differences**: Combine time and group variation\n",
    "\n",
    "3. **The innovative mindset**:\n",
    "   - Question conventional wisdom\n",
    "   - Look for creative solutions\n",
    "   - Exploit institutional features\n",
    "   - Think like a detective\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- üö´ **Don't accept \"we can't randomize\" as the end of the conversation**\n",
    "- üîç **Look for sources of random or quasi-random variation**\n",
    "- üèóÔ∏è **Exploit institutional rules and arbitrary cutoffs**\n",
    "- ‚è∞ **Use time and policy changes to your advantage**\n",
    "- üß† **Creative thinking is your most powerful tool**\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Continue your journey of innovation with:\n",
    "- **Tutorial 2**: Seeing Different - Identifying hidden causal relationships\n",
    "- **Tutorial 3**: The Crazy Idea - Using ML for causal inference\n",
    "- **Tutorial 4**: Change Things - From analysis to intervention\n",
    "\n",
    "---\n",
    "\n",
    "*\"The people who are crazy enough to think they can change the world are the ones who do.\" - Keep breaking rules and discovering truth!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
