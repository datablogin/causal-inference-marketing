{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method Comparison: G-computation, IPW, and AIPW\n",
    "\n",
    "This notebook compares different causal inference methods on the same dataset to demonstrate their relative strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from causal_inference.core import CovariateData, OutcomeData, TreatmentData\n",
    "from causal_inference.estimators import AIPW, IPW, GComputation\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use(\"default\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data with Known Treatment Effect\n",
    "\n",
    "We'll create data where we know the true causal effect is 0.15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "n = 2000\n",
    "\n",
    "# Confounders\n",
    "X1 = np.random.normal(0, 1, n)\n",
    "X2 = np.random.normal(0, 1, n)\n",
    "X3 = np.random.binomial(1, 0.5, n)\n",
    "\n",
    "# Treatment assignment (depends on confounders)\n",
    "treatment_logit = -0.5 + 0.5 * X1 + 0.3 * X2 + 0.4 * X3\n",
    "treatment_prob = 1 / (1 + np.exp(-treatment_logit))\n",
    "treatment = np.random.binomial(1, treatment_prob, n)\n",
    "\n",
    "# Outcome (depends on both treatment and confounders)\n",
    "# TRUE CAUSAL EFFECT = 0.15\n",
    "outcome_logit = -1 + 0.15 * treatment + 0.4 * X1 + 0.3 * X2 + 0.2 * X3\n",
    "outcome_prob = 1 / (1 + np.exp(-outcome_logit))\n",
    "outcome = np.random.binomial(1, outcome_prob, n)\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame(\n",
    "    {\"X1\": X1, \"X2\": X2, \"X3\": X3, \"treatment\": treatment, \"outcome\": outcome}\n",
    ")\n",
    "\n",
    "print(f\"Sample size: {n}\")\n",
    "print(f\"Treatment rate: {treatment.mean():.3f}\")\n",
    "print(f\"Outcome rate: {outcome.mean():.3f}\")\n",
    "print(\"True causal effect: 0.150\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Data Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define causal inference data objects\n",
    "treatment_data = TreatmentData(\n",
    "    values=data[\"treatment\"], name=\"treatment\", treatment_type=\"binary\"\n",
    ")\n",
    "\n",
    "outcome_data = OutcomeData(\n",
    "    values=data[\"outcome\"], name=\"outcome\", outcome_type=\"binary\"\n",
    ")\n",
    "\n",
    "covariate_data = CovariateData(\n",
    "    values=data[[\"X1\", \"X2\", \"X3\"]], names=[\"X1\", \"X2\", \"X3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize estimators\n",
    "methods = {\n",
    "    \"G-computation\": GComputation(),\n",
    "    \"IPW\": IPW(),\n",
    "    \"AIPW (Doubly Robust)\": AIPW(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Estimate effects with each method\n",
    "for name, estimator in methods.items():\n",
    "    effect = estimator.estimate_ate(\n",
    "        treatment=treatment_data, outcome=outcome_data, covariates=covariate_data\n",
    "    )\n",
    "\n",
    "    results[name] = {\n",
    "        \"ate\": effect.ate,\n",
    "        \"se\": effect.se,\n",
    "        \"ci_lower\": effect.ci_lower,\n",
    "        \"ci_upper\": effect.ci_upper,\n",
    "        \"p_value\": effect.p_value,\n",
    "    }\n",
    "\n",
    "# Also compute naive difference\n",
    "treated_mean = data[data[\"treatment\"] == 1][\"outcome\"].mean()\n",
    "control_mean = data[data[\"treatment\"] == 0][\"outcome\"].mean()\n",
    "naive_diff = treated_mean - control_mean\n",
    "\n",
    "results[\"Naive Difference\"] = {\n",
    "    \"ate\": naive_diff,\n",
    "    \"se\": np.nan,\n",
    "    \"ci_lower\": np.nan,\n",
    "    \"ci_upper\": np.nan,\n",
    "    \"p_value\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df[\"bias\"] = results_df[\"ate\"] - 0.150  # True effect is 0.15\n",
    "results_df[\"abs_bias\"] = np.abs(results_df[\"bias\"])\n",
    "\n",
    "print(\"ðŸ“Š Method Comparison Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Method':<20} {'ATE':<8} {'SE':<8} {'95% CI':<20} {'Bias':<8}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for method, row in results_df.iterrows():\n",
    "    ate_str = f\"{row['ate']:.4f}\"\n",
    "    se_str = f\"{row['se']:.4f}\" if not pd.isna(row[\"se\"]) else \"N/A\"\n",
    "    ci_str = (\n",
    "        f\"[{row['ci_lower']:.3f}, {row['ci_upper']:.3f}]\"\n",
    "        if not pd.isna(row[\"ci_lower\"])\n",
    "        else \"N/A\"\n",
    "    )\n",
    "    bias_str = f\"{row['bias']:.4f}\"\n",
    "\n",
    "    print(f\"{method:<20} {ate_str:<8} {se_str:<8} {ci_str:<20} {bias_str:<8}\")\n",
    "\n",
    "print(\"\\nTrue causal effect: 0.150\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Point estimates with confidence intervals\n",
    "methods_plot = [m for m in results_df.index if m != \"Naive Difference\"]\n",
    "ates = [results_df.loc[m, \"ate\"] for m in methods_plot]\n",
    "ses = [results_df.loc[m, \"se\"] for m in methods_plot]\n",
    "ci_lowers = [results_df.loc[m, \"ci_lower\"] for m in methods_plot]\n",
    "ci_uppers = [results_df.loc[m, \"ci_upper\"] for m in methods_plot]\n",
    "\n",
    "y_pos = range(len(methods_plot))\n",
    "\n",
    "ax1.errorbar(\n",
    "    ates,\n",
    "    y_pos,\n",
    "    xerr=[np.array(ates) - np.array(ci_lowers), np.array(ci_uppers) - np.array(ates)],\n",
    "    fmt=\"o\",\n",
    "    capsize=5,\n",
    "    capthick=2,\n",
    "    markersize=8,\n",
    ")\n",
    "\n",
    "# Add true effect line\n",
    "ax1.axvline(x=0.150, color=\"red\", linestyle=\"--\", linewidth=2, label=\"True Effect\")\n",
    "\n",
    "# Add naive estimate\n",
    "ax1.axvline(\n",
    "    x=naive_diff, color=\"gray\", linestyle=\":\", linewidth=2, label=\"Naive Difference\"\n",
    ")\n",
    "\n",
    "ax1.set_yticks(y_pos)\n",
    "ax1.set_yticklabels(methods_plot)\n",
    "ax1.set_xlabel(\"Average Treatment Effect\")\n",
    "ax1.set_title(\"ATE Estimates with 95% Confidence Intervals\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Bias comparison\n",
    "all_methods = list(results_df.index)\n",
    "biases = [results_df.loc[m, \"bias\"] for m in all_methods]\n",
    "\n",
    "colors = [\n",
    "    \"blue\"\n",
    "    if \"AIPW\" in m\n",
    "    else \"green\"\n",
    "    if m == \"G-computation\"\n",
    "    else \"orange\"\n",
    "    if m == \"IPW\"\n",
    "    else \"red\"\n",
    "    for m in all_methods\n",
    "]\n",
    "\n",
    "bars = ax2.bar(range(len(all_methods)), biases, color=colors, alpha=0.7)\n",
    "ax2.axhline(y=0, color=\"black\", linestyle=\"-\", linewidth=1)\n",
    "ax2.set_xticks(range(len(all_methods)))\n",
    "ax2.set_xticklabels(\n",
    "    [m.replace(\" \", \"\\n\") for m in all_methods], rotation=45, ha=\"right\"\n",
    ")\n",
    "ax2.set_ylabel(\"Bias (Estimate - True Effect)\")\n",
    "ax2.set_title(\"Bias Comparison\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Naive Difference** is biased due to confounding\n",
    "2. **G-computation** works well when the outcome model is correct\n",
    "3. **IPW** works well when the propensity model is correct\n",
    "4. **AIPW** is \"doubly robust\" - works if either model is correct\n",
    "\n",
    "In practice, AIPW is often preferred because it provides protection against model misspecification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis\n",
    "\n",
    "Let's see how sensitive our results are to model specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different model complexities\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_configs = {\n",
    "    \"Linear Models\": {\n",
    "        \"outcome_model\": LogisticRegression(),\n",
    "        \"propensity_model\": LogisticRegression(),\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"outcome_model\": RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "        \"propensity_model\": RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"ðŸ” Sensitivity to Model Choice\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for config_name, models in model_configs.items():\n",
    "    # Test AIPW with different models\n",
    "    aipw = AIPW(**models)\n",
    "    effect = aipw.estimate_ate(\n",
    "        treatment=treatment_data, outcome=outcome_data, covariates=covariate_data\n",
    "    )\n",
    "\n",
    "    bias = effect.ate - 0.150\n",
    "    print(f\"{config_name}: ATE = {effect.ate:.4f}, Bias = {bias:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
