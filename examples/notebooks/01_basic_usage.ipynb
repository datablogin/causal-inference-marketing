{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage of Causal Inference Library\n",
    "\n",
    "This notebook demonstrates the basic usage of the causal inference library for marketing applications.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll cover:\n",
    "1. Data preparation and validation\n",
    "2. Basic causal inference with G-computation\n",
    "3. Inverse Probability Weighting (IPW)\n",
    "4. Augmented IPW (AIPW) - doubly robust estimation\n",
    "5. Diagnostics and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\n\n# Add the project root to Python path for development mode compatibility\nproject_root = os.path.abspath(os.path.join(os.getcwd(), '../../'))\nif project_root not in sys.path:\n    sys.path.insert(0, os.path.join(project_root, 'libs'))\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Import causal inference components\nfrom causal_inference.core.base import TreatmentData, OutcomeData, CovariateData\nfrom causal_inference.estimators.g_computation import GComputationEstimator\nfrom causal_inference.estimators.ipw import IPWEstimator\nfrom causal_inference.estimators.aipw import AIPWEstimator\nfrom causal_inference.data.synthetic import SyntheticDataGenerator\nfrom causal_inference.data.validation import validate_causal_data\nfrom causal_inference.diagnostics.balance import check_covariate_balance\nfrom causal_inference.diagnostics.overlap import assess_positivity\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Configure plotting\nplt.style.use('default')\nsns.set_palette(\"husl\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation and Preparation\n",
    "\n",
    "Let's start by generating synthetic data that mimics a marketing campaign scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic marketing campaign data\n",
    "generator = SyntheticDataGenerator(random_state=42)\n",
    "\n",
    "# Generate data for email campaign effectiveness study\n",
    "treatment, outcome, covariates = generator.generate_linear_binary_treatment(\n",
    "    n_samples=1000,\n",
    "    n_confounders=4,\n",
    "    treatment_effect=2.5,  # True ATE of $2.50 increase in purchase amount\n",
    "    confounding_strength=0.5\n",
    ")\n",
    "\n",
    "print(f\"Generated data with {len(treatment.values)} samples\")\n",
    "print(f\"Treatment type: {treatment.treatment_type}\")\n",
    "print(f\"Outcome type: {outcome.outcome_type}\")\n",
    "print(f\"Number of covariates: {covariates.values.shape[1]}\")\n",
    "print(f\"Treatment distribution: {np.bincount(treatment.values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the data\n",
    "data_df = pd.DataFrame({\n",
    "    'treatment': treatment.values,\n",
    "    'outcome': outcome.values,\n",
    "    **{f'covariate_{i}': covariates.values.iloc[:, i] for i in range(covariates.values.shape[1])}\n",
    "})\n",
    "\n",
    "print(\"Data summary:\")\n",
    "print(data_df.describe())\n",
    "\n",
    "# Visualize treatment and outcome distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Treatment distribution\n",
    "axes[0].bar(['Control', 'Treatment'], np.bincount(treatment.values))\n",
    "axes[0].set_title('Treatment Distribution')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Outcome by treatment\n",
    "sns.boxplot(data=data_df, x='treatment', y='outcome', ax=axes[1])\n",
    "axes[1].set_title('Outcome by Treatment')\n",
    "axes[1].set_xlabel('Treatment Group')\n",
    "\n",
    "# Covariate correlation\n",
    "covariate_corr = covariates.values.corr()\n",
    "sns.heatmap(covariate_corr, annot=True, ax=axes[2])\n",
    "axes[2].set_title('Covariate Correlations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Validation\n",
    "\n",
    "Before running causal inference, let's validate our data to check for potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the causal data\n",
    "validation_result = validate_causal_data(\n",
    "    treatment=treatment,\n",
    "    outcome=outcome,\n",
    "    covariates=covariates,\n",
    "    check_overlap=True\n",
    ")\n",
    "\n",
    "print(\"Data validation completed successfully!\")\n",
    "print(f\"Sample size: {len(treatment.values)}\")\n",
    "print(f\"Treatment variation: {len(np.unique(treatment.values))} unique values\")\n",
    "print(f\"No missing values: {not pd.isnull(covariates.values).any().any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Causal Inference with G-Computation\n",
    "\n",
    "G-computation (standardization) estimates the ATE by predicting potential outcomes under different treatment scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize G-computation estimator\n",
    "g_comp = GComputationEstimator(\n",
    "    outcome_model='linear',  # Linear regression for continuous outcomes\n",
    "    bootstrap_samples=100   # For confidence intervals\n",
    ")\n",
    "\n",
    "# Fit the estimator\n",
    "print(\"Fitting G-computation estimator...\")\n",
    "g_comp.fit(treatment, outcome, covariates)\n",
    "\n",
    "# Estimate the Average Treatment Effect (ATE)\n",
    "g_comp_effect = g_comp.estimate_ate()\n",
    "\n",
    "print(\"\\n=== G-Computation Results ===\")\n",
    "print(f\"Estimated ATE: ${g_comp_effect.ate:.2f}\")\n",
    "print(f\"95% Confidence Interval: [${g_comp_effect.confidence_interval[0]:.2f}, ${g_comp_effect.confidence_interval[1]:.2f}]\")\n",
    "print(f\"Effect is significant: {g_comp_effect.is_significant}\")\n",
    "print(f\"True ATE: $2.50\")\n",
    "\n",
    "# Get detailed summary\n",
    "print(\"\\nDetailed Summary:\")\n",
    "print(g_comp.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inverse Probability Weighting (IPW)\n",
    "\n",
    "IPW estimates the ATE by reweighting observations based on the propensity score (probability of receiving treatment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IPW estimator\n",
    "ipw = IPWEstimator(\n",
    "    propensity_model='logistic',  # Logistic regression for binary treatment\n",
    "    stabilize_weights=True,       # Use stabilized weights\n",
    "    weight_truncation='percentile',  # Truncate extreme weights\n",
    "    bootstrap_samples=100\n",
    ")\n",
    "\n",
    "# Fit the estimator\n",
    "print(\"Fitting IPW estimator...\")\n",
    "ipw.fit(treatment, outcome, covariates)\n",
    "\n",
    "# Estimate ATE\n",
    "ipw_effect = ipw.estimate_ate()\n",
    "\n",
    "print(\"\\n=== IPW Results ===\")\n",
    "print(f\"Estimated ATE: ${ipw_effect.ate:.2f}\")\n",
    "print(f\"95% Confidence Interval: [${ipw_effect.confidence_interval[0]:.2f}, ${ipw_effect.confidence_interval[1]:.2f}]\")\n",
    "print(f\"Effect is significant: {ipw_effect.is_significant}\")\n",
    "\n",
    "# Check weight distribution\n",
    "weights = ipw._compute_weights()\n",
    "print(f\"\\nWeight statistics:\")\n",
    "print(f\"Mean weight: {np.mean(weights):.3f}\")\n",
    "print(f\"Weight range: [{np.min(weights):.3f}, {np.max(weights):.3f}]\")\n",
    "print(f\"Weight variance: {np.var(weights):.3f}\")\n",
    "\n",
    "# Plot weight distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(weights, bins=30, alpha=0.7)\n",
    "plt.title('Distribution of IPW Weights')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "treated_weights = weights[treatment.values == 1]\n",
    "control_weights = weights[treatment.values == 0]\n",
    "plt.hist(treated_weights, bins=20, alpha=0.7, label='Treated')\n",
    "plt.hist(control_weights, bins=20, alpha=0.7, label='Control')\n",
    "plt.title('Weights by Treatment Group')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Augmented IPW (AIPW) - Doubly Robust\n",
    "\n",
    "AIPW combines G-computation and IPW to create a doubly robust estimator that is consistent if either the outcome model or propensity model is correctly specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AIPW estimator\n",
    "aipw = AIPWEstimator(\n",
    "    outcome_model='linear',\n",
    "    propensity_model='logistic',\n",
    "    bootstrap_samples=100\n",
    ")\n",
    "\n",
    "# Fit the estimator\n",
    "print(\"Fitting AIPW estimator...\")\n",
    "aipw.fit(treatment, outcome, covariates)\n",
    "\n",
    "# Estimate ATE\n",
    "aipw_effect = aipw.estimate_ate()\n",
    "\n",
    "print(\"\\n=== AIPW Results ===\")\n",
    "print(f\"Estimated ATE: ${aipw_effect.ate:.2f}\")\n",
    "print(f\"95% Confidence Interval: [${aipw_effect.confidence_interval[0]:.2f}, ${aipw_effect.confidence_interval[1]:.2f}]\")\n",
    "print(f\"Effect is significant: {aipw_effect.is_significant}\")\n",
    "\n",
    "print(\"\\nDetailed Summary:\")\n",
    "print(aipw.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison of Methods\n",
    "\n",
    "Let's compare all three methods and see how they perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\n",
    "results = {\n",
    "    'Method': ['G-Computation', 'IPW', 'AIPW', 'True ATE'],\n",
    "    'ATE': [g_comp_effect.ate, ipw_effect.ate, aipw_effect.ate, 2.5],\n",
    "    'CI_Lower': [g_comp_effect.confidence_interval[0], \n",
    "                 ipw_effect.confidence_interval[0], \n",
    "                 aipw_effect.confidence_interval[0], \n",
    "                 np.nan],\n",
    "    'CI_Upper': [g_comp_effect.confidence_interval[1], \n",
    "                 ipw_effect.confidence_interval[1], \n",
    "                 aipw_effect.confidence_interval[1], \n",
    "                 np.nan],\n",
    "    'Significant': [g_comp_effect.is_significant, \n",
    "                   ipw_effect.is_significant, \n",
    "                   aipw_effect.is_significant, \n",
    "                   True]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Comparison of Methods ===\")\n",
    "print(results_df.round(3))\n",
    "\n",
    "# Visualize results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "methods = ['G-Computation', 'IPW', 'AIPW']\n",
    "ates = [g_comp_effect.ate, ipw_effect.ate, aipw_effect.ate]\n",
    "cis_lower = [g_comp_effect.confidence_interval[0], \n",
    "             ipw_effect.confidence_interval[0], \n",
    "             aipw_effect.confidence_interval[0]]\n",
    "cis_upper = [g_comp_effect.confidence_interval[1], \n",
    "             ipw_effect.confidence_interval[1], \n",
    "             aipw_effect.confidence_interval[1]]\n",
    "\n",
    "# Plot point estimates and confidence intervals\n",
    "x_pos = np.arange(len(methods))\n",
    "ax.errorbar(x_pos, ates, \n",
    "           yerr=[np.array(ates) - np.array(cis_lower), \n",
    "                 np.array(cis_upper) - np.array(ates)], \n",
    "           fmt='o', capsize=5, capthick=2, markersize=8)\n",
    "\n",
    "# Add true ATE line\n",
    "ax.axhline(y=2.5, color='red', linestyle='--', alpha=0.7, label='True ATE')\n",
    "\n",
    "ax.set_xlabel('Method')\n",
    "ax.set_ylabel('Average Treatment Effect ($)')\n",
    "ax.set_title('Comparison of Causal Inference Methods')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate bias and coverage\n",
    "true_ate = 2.5\n",
    "print(\"\\n=== Method Performance ===\")\n",
    "for i, method in enumerate(methods):\n",
    "    bias = ates[i] - true_ate\n",
    "    covers_truth = cis_lower[i] <= true_ate <= cis_upper[i]\n",
    "    ci_width = cis_upper[i] - cis_lower[i]\n",
    "    \n",
    "    print(f\"{method}:\")\n",
    "    print(f\"  Bias: ${bias:.3f}\")\n",
    "    print(f\"  CI Width: ${ci_width:.3f}\")\n",
    "    print(f\"  Covers Truth: {covers_truth}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Diagnostics and Assumptions\n",
    "\n",
    "Let's check key assumptions for causal inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check covariate balance\n",
    "print(\"=== Covariate Balance Assessment ===\")\n",
    "balance_result = check_covariate_balance(treatment, covariates)\n",
    "\n",
    "balance_table = balance_result['balance_table']\n",
    "print(\"\\nStandardized Mean Differences:\")\n",
    "print(balance_table[['Variable', 'SMD', 'Balanced']].round(3))\n",
    "\n",
    "# Check overlap/positivity\n",
    "print(\"\\n=== Overlap Assessment ===\")\n",
    "overlap_result = assess_positivity(treatment, covariates)\n",
    "\n",
    "print(f\"Common support satisfied: {overlap_result['common_support']}\")\n",
    "print(f\"Propensity score range: [{overlap_result['propensity_range'][0]:.3f}, {overlap_result['propensity_range'][1]:.3f}]\")\n",
    "\n",
    "# Plot propensity score distributions\n",
    "propensity_scores = overlap_result['propensity_scores']\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "treated_ps = propensity_scores[treatment.values == 1]\n",
    "control_ps = propensity_scores[treatment.values == 0]\n",
    "\n",
    "plt.hist(control_ps, bins=30, alpha=0.7, label='Control', density=True)\n",
    "plt.hist(treated_ps, bins=30, alpha=0.7, label='Treated', density=True)\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Propensity Score Distribution by Treatment')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "smd_values = balance_table['SMD'].values\n",
    "variables = balance_table['Variable'].values\n",
    "\n",
    "colors = ['green' if abs(smd) < 0.1 else 'orange' if abs(smd) < 0.2 else 'red' for smd in smd_values]\n",
    "plt.barh(variables, smd_values, color=colors)\n",
    "plt.axvline(x=0.1, color='orange', linestyle='--', alpha=0.7, label='SMD = 0.1')\n",
    "plt.axvline(x=-0.1, color='orange', linestyle='--', alpha=0.7)\n",
    "plt.axvline(x=0.2, color='red', linestyle='--', alpha=0.7, label='SMD = 0.2')\n",
    "plt.axvline(x=-0.2, color='red', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('Standardized Mean Difference')\n",
    "plt.title('Covariate Balance')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interpretation and Conclusions\n",
    "\n",
    "Let's interpret our results in the context of the marketing campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Marketing Campaign Analysis Summary ===\")\n",
    "print()\n",
    "print(\"RESEARCH QUESTION:\")\n",
    "print(\"What is the causal effect of email marketing campaigns on customer purchase amounts?\")\n",
    "print()\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(f\"• All three methods estimate a positive treatment effect\")\n",
    "print(f\"• AIPW (doubly robust) estimate: ${aipw_effect.ate:.2f} increase in purchase amount\")\n",
    "print(f\"• 95% confidence interval: [${aipw_effect.confidence_interval[0]:.2f}, ${aipw_effect.confidence_interval[1]:.2f}]\")\n",
    "print(f\"• Effect is statistically significant: {aipw_effect.is_significant}\")\n",
    "print()\n",
    "print(\"BUSINESS IMPLICATIONS:\")\n",
    "print(f\"• Email campaigns increase average customer spending by approximately ${aipw_effect.ate:.2f}\")\n",
    "print(f\"• This represents a meaningful lift for marketing ROI calculations\")\n",
    "print(f\"• Results are robust across different estimation methods\")\n",
    "print()\n",
    "print(\"METHODOLOGICAL NOTES:\")\n",
    "print(f\"• Covariate balance: {'Good' if balance_result['overall_balance'] else 'Needs attention'}\")\n",
    "print(f\"• Overlap assumption: {'Satisfied' if overlap_result['common_support'] else 'Violated'}\")\n",
    "print(f\"• Sample size: {len(treatment.values)} customers\")\n",
    "print(f\"• Treatment rate: {np.mean(treatment.values):.1%}\")\n",
    "\n",
    "# Calculate potential business impact\n",
    "avg_customers_per_month = 10000\n",
    "treatment_rate = 0.3  # 30% get email campaigns\n",
    "monthly_treated = avg_customers_per_month * treatment_rate\n",
    "monthly_lift = monthly_treated * aipw_effect.ate\n",
    "annual_lift = monthly_lift * 12\n",
    "\n",
    "print()\n",
    "print(\"PROJECTED BUSINESS IMPACT:\")\n",
    "print(f\"• Assuming {avg_customers_per_month:,} customers/month with {treatment_rate:.0%} treatment rate:\")\n",
    "print(f\"• Monthly revenue lift: ${monthly_lift:,.0f}\")\n",
    "print(f\"• Annual revenue lift: ${annual_lift:,.0f}\")\n",
    "print()\n",
    "print(\"RECOMMENDATIONS:\")\n",
    "print(\"• Continue email marketing campaigns - they show clear positive impact\")\n",
    "print(\"• Consider expanding treatment to more customers if cost-effective\")\n",
    "print(\"• Monitor results over time to ensure effect persistence\")\n",
    "print(\"• Consider testing different email content or timing for optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook covered the basics of causal inference for marketing applications. For more advanced topics, see:\n",
    "\n",
    "1. **Marketing Use Cases** (`02_marketing_use_cases.ipynb`) - Specific marketing scenarios\n",
    "2. **Advanced Diagnostics** (`03_advanced_diagnostics.ipynb`) - Detailed assumption checking\n",
    "3. **Sensitivity Analysis** (`04_sensitivity_analysis.ipynb`) - Robustness testing\n",
    "4. **Real Data Example** (`05_real_data_example.ipynb`) - Working with actual datasets\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Multiple methods**: Use G-computation, IPW, and AIPW to triangulate results\n",
    "2. **Diagnostics are crucial**: Always check balance, overlap, and other assumptions\n",
    "3. **AIPW is robust**: Doubly robust methods provide insurance against model misspecification\n",
    "4. **Business context matters**: Translate statistical results into actionable business insights\n",
    "5. **Validation is key**: Use synthetic data to validate methods before applying to real data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}