{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marketing Use Cases for Causal Inference\n",
    "\n",
    "This notebook demonstrates specific marketing use cases where causal inference provides valuable insights.\n",
    "\n",
    "## Use Cases Covered\n",
    "\n",
    "1. **Email Marketing Campaign Effectiveness**\n",
    "2. **Price Promotion Impact Analysis**\n",
    "3. **Customer Loyalty Program Evaluation**\n",
    "4. **A/B Testing with Observational Data**\n",
    "5. **Media Channel Attribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "# Import causal inference components\n",
    "from causal_inference.core.base import TreatmentData, OutcomeData, CovariateData\n",
    "from causal_inference.estimators.g_computation import GComputationEstimator\n",
    "from causal_inference.estimators.ipw import IPWEstimator\n",
    "from causal_inference.estimators.aipw import AIPWEstimator\n",
    "from causal_inference.data.synthetic import SyntheticDataGenerator\n",
    "from causal_inference.diagnostics.balance import check_covariate_balance\n",
    "from causal_inference.diagnostics.reporting import generate_diagnostic_report\n",
    "\n",
    "# Set random seed and plotting style\n",
    "np.random.seed(42)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 1: Email Marketing Campaign Effectiveness\n",
    "\n",
    "**Business Question**: Does sending promotional emails increase customer purchases?\n",
    "\n",
    "**Challenge**: Customers aren't randomly assigned emails - targeting is based on past behavior, demographics, and engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic email marketing data\n",
    "np.random.seed(123)\n",
    "n_customers = 2000\n",
    "\n",
    "# Customer characteristics\n",
    "age = np.random.uniform(18, 70, n_customers)\n",
    "income = np.random.lognormal(10.5, 0.5, n_customers)  # Log-normal income distribution\n",
    "past_purchases = np.random.poisson(3, n_customers)  # Historic purchase count\n",
    "email_engagement = np.random.beta(2, 5, n_customers)  # Past email open rates\n",
    "days_since_last_purchase = np.random.exponential(30, n_customers)\n",
    "\n",
    "# Email targeting is based on customer characteristics (confounding!)\n",
    "email_propensity = (\n",
    "    -2.5 +  # Base propensity\n",
    "    0.02 * age +  # Older customers more likely to get emails\n",
    "    0.00001 * income +  # Higher income customers\n",
    "    0.3 * past_purchases +  # Frequent buyers\n",
    "    2.0 * email_engagement +  # High engagement\n",
    "    -0.01 * days_since_last_purchase  # Recent customers\n",
    ")\n",
    "\n",
    "email_prob = 1 / (1 + np.exp(-email_propensity))\n",
    "received_email = np.random.binomial(1, email_prob, n_customers)\n",
    "\n",
    "# Purchase outcome depends on both customer characteristics AND email\n",
    "purchase_amount = (\n",
    "    50 +  # Base purchase amount\n",
    "    1.5 * age +  # Age effect\n",
    "    0.002 * income +  # Income effect\n",
    "    15 * past_purchases +  # Loyalty effect\n",
    "    100 * email_engagement +  # Engagement effect\n",
    "    -0.5 * days_since_last_purchase +  # Recency effect\n",
    "    25 * received_email +  # TRUE CAUSAL EFFECT of email\n",
    "    np.random.normal(0, 20, n_customers)  # Noise\n",
    ")\n",
    "\n",
    "purchase_amount = np.maximum(purchase_amount, 0)  # Non-negative purchases\n",
    "\n",
    "# Create data objects\n",
    "email_data = {\n",
    "    'treatment': TreatmentData(values=received_email, treatment_type=\"binary\"),\n",
    "    'outcome': OutcomeData(values=purchase_amount, outcome_type=\"continuous\"),\n",
    "    'covariates': CovariateData(values=pd.DataFrame({\n",
    "        'age': age,\n",
    "        'income': income,\n",
    "        'past_purchases': past_purchases,\n",
    "        'email_engagement': email_engagement,\n",
    "        'days_since_last_purchase': days_since_last_purchase\n",
    "    }))\n",
    "}\n",
    "\n",
    "print(f\"Email Marketing Dataset:\")\n",
    "print(f\"- {n_customers} customers\")\n",
    "print(f\"- {np.sum(received_email)} received emails ({np.mean(received_email):.1%})\")\n",
    "print(f\"- True email effect: $25\")\n",
    "print(f\"- Mean purchase amount: ${np.mean(purchase_amount):.2f}\")\n",
    "\n",
    "# Naive comparison (biased!)\n",
    "naive_diff = np.mean(purchase_amount[received_email == 1]) - np.mean(purchase_amount[received_email == 0])\n",
    "print(f\"- Naive difference: ${naive_diff:.2f} (biased due to confounding)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze email marketing with causal inference\n",
    "print(\"=== Email Marketing Causal Analysis ===\")\n",
    "\n",
    "# Use random forest models for flexibility\n",
    "aipw_email = AIPWEstimator(\n",
    "    outcome_model=RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    propensity_model=RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    bootstrap_samples=100\n",
    ")\n",
    "\n",
    "aipw_email.fit(email_data['treatment'], email_data['outcome'], email_data['covariates'])\n",
    "email_effect = aipw_email.estimate_ate()\n",
    "\n",
    "print(f\"\\nCausal Effect Results:\")\n",
    "print(f\"- Estimated ATE: ${email_effect.ate:.2f}\")\n",
    "print(f\"- 95% CI: [${email_effect.confidence_interval[0]:.2f}, ${email_effect.confidence_interval[1]:.2f}]\")\n",
    "print(f\"- True effect: $25.00\")\n",
    "print(f\"- Bias corrected: ${naive_diff - email_effect.ate:.2f}\")\n",
    "\n",
    "# Business implications\n",
    "total_customers = 50000  # Scale up\n",
    "current_email_rate = 0.3\n",
    "customers_emailed = total_customers * current_email_rate\n",
    "monthly_lift = customers_emailed * email_effect.ate\n",
    "annual_lift = monthly_lift * 12\n",
    "\n",
    "print(f\"\\nBusiness Impact (scaled to {total_customers:,} customers):\")\n",
    "print(f\"- Monthly revenue lift: ${monthly_lift:,.0f}\")\n",
    "print(f\"- Annual revenue lift: ${annual_lift:,.0f}\")\n",
    "\n",
    "# Check balance\n",
    "balance_result = check_covariate_balance(email_data['treatment'], email_data['covariates'])\n",
    "print(f\"\\nCovariate Balance: {'Good' if balance_result['overall_balance'] else 'Poor - confounding present'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 2: Price Promotion Impact Analysis\n",
    "\n",
    "**Business Question**: What's the true incremental impact of price discounts on sales?\n",
    "\n",
    "**Challenge**: Promotions are typically used on slow-moving products or during low-demand periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate price promotion data\n",
    "np.random.seed(456)\n",
    "n_products = 1500\n",
    "\n",
    "# Product characteristics\n",
    "base_price = np.random.uniform(10, 100, n_products)\n",
    "product_age = np.random.uniform(0, 365, n_products)  # Days since launch\n",
    "category_popularity = np.random.normal(0, 1, n_products)  # Standardized category appeal\n",
    "inventory_level = np.random.exponential(50, n_products)  # Inventory overstocking\n",
    "seasonality = np.sin(2 * np.pi * np.arange(n_products) / 365)  # Seasonal component\n",
    "\n",
    "# Promotions are more likely for overstocked, older, less popular products\n",
    "promotion_propensity = (\n",
    "    -1.0 +  # Base propensity\n",
    "    -0.02 * base_price +  # Cheaper products promoted more\n",
    "    0.005 * product_age +  # Older products\n",
    "    -0.5 * category_popularity +  # Less popular categories\n",
    "    0.01 * inventory_level +  # Overstocked items\n",
    "    -0.5 * seasonality  # Out-of-season items\n",
    ")\n",
    "\n",
    "promotion_prob = 1 / (1 + np.exp(-promotion_propensity))\n",
    "has_promotion = np.random.binomial(1, promotion_prob, n_products)\n",
    "\n",
    "# Sales depend on product characteristics AND promotion\n",
    "log_sales = (\n",
    "    3.0 +  # Base log sales\n",
    "    -0.02 * base_price +  # Price sensitivity\n",
    "    -0.001 * product_age +  # Newer products sell better\n",
    "    0.8 * category_popularity +  # Popular categories\n",
    "    -0.005 * inventory_level +  # Overstocked = lower demand\n",
    "    0.3 * seasonality +  # Seasonal effects\n",
    "    0.4 * has_promotion +  # TRUE CAUSAL EFFECT (40% sales lift)\n",
    "    np.random.normal(0, 0.3, n_products)  # Noise\n",
    ")\n",
    "\n",
    "sales_units = np.exp(log_sales)  # Convert to actual sales\n",
    "\n",
    "# Create promotion data\n",
    "promotion_data = {\n",
    "    'treatment': TreatmentData(values=has_promotion, treatment_type=\"binary\"),\n",
    "    'outcome': OutcomeData(values=sales_units, outcome_type=\"continuous\"),\n",
    "    'covariates': CovariateData(values=pd.DataFrame({\n",
    "        'base_price': base_price,\n",
    "        'product_age': product_age,\n",
    "        'category_popularity': category_popularity,\n",
    "        'inventory_level': inventory_level,\n",
    "        'seasonality': seasonality\n",
    "    }))\n",
    "}\n",
    "\n",
    "print(f\"Price Promotion Dataset:\")\n",
    "print(f\"- {n_products} products\")\n",
    "print(f\"- {np.sum(has_promotion)} on promotion ({np.mean(has_promotion):.1%})\")\n",
    "print(f\"- True promotion effect: 40% sales lift\")\n",
    "\n",
    "# Naive comparison\n",
    "naive_ratio = np.mean(sales_units[has_promotion == 1]) / np.mean(sales_units[has_promotion == 0])\n",
    "print(f\"- Naive sales ratio: {naive_ratio:.2f} (biased - promotions target low-selling products)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze promotion impact with causal inference\n",
    "print(\"=== Price Promotion Causal Analysis ===\")\n",
    "\n",
    "aipw_promotion = AIPWEstimator(\n",
    "    outcome_model=RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    propensity_model=RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    bootstrap_samples=100\n",
    ")\n",
    "\n",
    "aipw_promotion.fit(promotion_data['treatment'], promotion_data['outcome'], promotion_data['covariates'])\n",
    "promotion_effect = aipw_promotion.estimate_ate()\n",
    "\n",
    "# Convert to percentage effect\n",
    "baseline_sales = np.mean(sales_units[has_promotion == 0])\n",
    "percentage_lift = (promotion_effect.ate / baseline_sales) * 100\n",
    "\n",
    "print(f\"\\nCausal Effect Results:\")\n",
    "print(f\"- Estimated ATE: {promotion_effect.ate:.2f} additional units\")\n",
    "print(f\"- Percentage lift: {percentage_lift:.1f}%\")\n",
    "print(f\"- True effect: 40% sales lift\")\n",
    "print(f\"- 95% CI: [{(promotion_effect.confidence_interval[0]/baseline_sales)*100:.1f}%, {(promotion_effect.confidence_interval[1]/baseline_sales)*100:.1f}%]\")\n",
    "\n",
    "# Calculate ROI\n",
    "avg_price = np.mean(base_price)\n",
    "discount_rate = 0.20  # 20% discount\n",
    "cost_per_promotion = avg_price * discount_rate\n",
    "revenue_per_promotion = promotion_effect.ate * avg_price\n",
    "roi = (revenue_per_promotion - cost_per_promotion) / cost_per_promotion\n",
    "\n",
    "print(f\"\\nPromotion ROI Analysis:\")\n",
    "print(f\"- Average discount cost: ${cost_per_promotion:.2f} per product\")\n",
    "print(f\"- Additional revenue: ${revenue_per_promotion:.2f} per product\")\n",
    "print(f\"- ROI: {roi:.1%}\")\n",
    "\n",
    "if roi > 0:\n",
    "    print(f\"- Recommendation: Promotions are profitable - continue strategy\")\n",
    "else:\n",
    "    print(f\"- Recommendation: Promotions are unprofitable - reconsider strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 3: Customer Loyalty Program Evaluation\n",
    "\n",
    "**Business Question**: Do loyalty programs increase customer lifetime value?\n",
    "\n",
    "**Challenge**: High-value customers are more likely to join loyalty programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate loyalty program data\n",
    "np.random.seed(789)\n",
    "n_customers = 3000\n",
    "\n",
    "# Customer characteristics\n",
    "customer_age = np.random.uniform(25, 65, n_customers)\n",
    "income_segment = np.random.choice([1, 2, 3], n_customers, p=[0.3, 0.5, 0.2])  # Low, Mid, High\n",
    "frequency_segment = np.random.choice([1, 2, 3], n_customers, p=[0.4, 0.4, 0.2])  # Low, Mid, High\n",
    "years_as_customer = np.random.exponential(2, n_customers)\n",
    "channel_preference = np.random.choice([0, 1], n_customers, p=[0.6, 0.4])  # Online vs Store\n",
    "\n",
    "# Loyalty program enrollment (selection bias!)\n",
    "loyalty_propensity = (\n",
    "    -3.0 +  # Base propensity\n",
    "    0.03 * customer_age +  # Older customers more likely\n",
    "    0.8 * income_segment +  # Higher income\n",
    "    1.2 * frequency_segment +  # Higher frequency customers\n",
    "    0.3 * years_as_customer +  # Long-term customers\n",
    "    0.5 * channel_preference  # Store shoppers more likely\n",
    ")\n",
    "\n",
    "loyalty_prob = 1 / (1 + np.exp(-loyalty_propensity))\n",
    "in_loyalty_program = np.random.binomial(1, loyalty_prob, n_customers)\n",
    "\n",
    "# Annual spend depends on characteristics AND loyalty program\n",
    "annual_spend = (\n",
    "    1000 +  # Base spend\n",
    "    20 * customer_age +  # Age effect\n",
    "    800 * income_segment +  # Income effect\n",
    "    600 * frequency_segment +  # Frequency effect\n",
    "    100 * years_as_customer +  # Tenure effect\n",
    "    200 * channel_preference +  # Channel effect\n",
    "    300 * in_loyalty_program +  # TRUE CAUSAL EFFECT\n",
    "    np.random.normal(0, 400, n_customers)  # Noise\n",
    ")\n",
    "\n",
    "annual_spend = np.maximum(annual_spend, 100)  # Minimum spend\n",
    "\n",
    "# Create loyalty data\n",
    "loyalty_data = {\n",
    "    'treatment': TreatmentData(values=in_loyalty_program, treatment_type=\"binary\"),\n",
    "    'outcome': OutcomeData(values=annual_spend, outcome_type=\"continuous\"),\n",
    "    'covariates': CovariateData(values=pd.DataFrame({\n",
    "        'customer_age': customer_age,\n",
    "        'income_segment': income_segment,\n",
    "        'frequency_segment': frequency_segment,\n",
    "        'years_as_customer': years_as_customer,\n",
    "        'channel_preference': channel_preference\n",
    "    }))\n",
    "}\n",
    "\n",
    "print(f\"Loyalty Program Dataset:\")\n",
    "print(f\"- {n_customers} customers\")\n",
    "print(f\"- {np.sum(in_loyalty_program)} in loyalty program ({np.mean(in_loyalty_program):.1%})\")\n",
    "print(f\"- True loyalty effect: $300 additional annual spend\")\n",
    "\n",
    "# Naive comparison\n",
    "naive_diff = np.mean(annual_spend[in_loyalty_program == 1]) - np.mean(annual_spend[in_loyalty_program == 0])\n",
    "print(f\"- Naive difference: ${naive_diff:.0f} (biased - high-value customers join more)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze loyalty program with causal inference\n",
    "print(\"=== Loyalty Program Causal Analysis ===\")\n",
    "\n",
    "aipw_loyalty = AIPWEstimator(\n",
    "    outcome_model=RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    propensity_model=RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    bootstrap_samples=100\n",
    ")\n",
    "\n",
    "aipw_loyalty.fit(loyalty_data['treatment'], loyalty_data['outcome'], loyalty_data['covariates'])\n",
    "loyalty_effect = aipw_loyalty.estimate_ate()\n",
    "\n",
    "print(f\"\\nCausal Effect Results:\")\n",
    "print(f\"- Estimated ATE: ${loyalty_effect.ate:.0f} additional annual spend\")\n",
    "print(f\"- 95% CI: [${loyalty_effect.confidence_interval[0]:.0f}, ${loyalty_effect.confidence_interval[1]:.0f}]\")\n",
    "print(f\"- True effect: $300\")\n",
    "print(f\"- Selection bias: ${naive_diff - loyalty_effect.ate:.0f}\")\n",
    "\n",
    "# Program economics\n",
    "program_cost_per_member = 50  # Annual cost to run program per member\n",
    "net_value = loyalty_effect.ate - program_cost_per_member\n",
    "roi_loyalty = net_value / program_cost_per_member\n",
    "\n",
    "current_members = 50000\n",
    "total_net_value = current_members * net_value\n",
    "\n",
    "print(f\"\\nProgram Economics:\")\n",
    "print(f\"- Program cost per member: ${program_cost_per_member}/year\")\n",
    "print(f\"- Net value per member: ${net_value:.0f}/year\")\n",
    "print(f\"- ROI: {roi_loyalty:.1%}\")\n",
    "print(f\"- Total net value ({current_members:,} members): ${total_net_value:,.0f}/year\")\n",
    "\n",
    "if net_value > 0:\n",
    "    print(f\"- Recommendation: Loyalty program is profitable - consider expansion\")\n",
    "else:\n",
    "    print(f\"- Recommendation: Loyalty program is unprofitable - needs restructuring\")\n",
    "\n",
    "# Visualize the effect\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "# Show bias in naive analysis\n",
    "methods = ['Naive\\nComparison', 'Causal\\nInference', 'True\\nEffect']\n",
    "effects = [naive_diff, loyalty_effect.ate, 300]\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "bars = plt.bar(methods, effects, color=colors, alpha=0.7)\n",
    "plt.title('Loyalty Program Effect: Naive vs Causal')\n",
    "plt.ylabel('Additional Annual Spend ($)')\n",
    "\n",
    "# Add value labels\n",
    "for bar, effect in zip(bars, effects):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10, \n",
    "             f'${effect:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Show distribution of annual spend by loyalty status\n",
    "loyalty_spend = annual_spend[in_loyalty_program == 1]\n",
    "non_loyalty_spend = annual_spend[in_loyalty_program == 0]\n",
    "\n",
    "plt.hist(non_loyalty_spend, bins=30, alpha=0.7, label='Non-Loyalty', density=True)\n",
    "plt.hist(loyalty_spend, bins=30, alpha=0.7, label='Loyalty', density=True)\n",
    "plt.xlabel('Annual Spend ($)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Spend Distribution by Loyalty Status')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Key Marketing Insights\n",
    "\n",
    "### Email Marketing\n",
    "- **Finding**: Emails have a significant positive effect on purchases\n",
    "- **Key Learning**: Naive analysis overestimates impact due to targeting bias\n",
    "- **Action**: Continue email campaigns but account for true incremental lift\n",
    "\n",
    "### Price Promotions  \n",
    "- **Finding**: Promotions drive meaningful sales lift despite targeting slow products\n",
    "- **Key Learning**: ROI analysis shows promotions can be profitable when effect is measured correctly\n",
    "- **Action**: Expand promotional strategy with better targeting\n",
    "\n",
    "### Loyalty Programs\n",
    "- **Finding**: Programs genuinely increase customer value beyond selection effects\n",
    "- **Key Learning**: High-value customers joining creates massive selection bias in naive analysis\n",
    "- **Action**: Invest in program expansion given positive true ROI\n",
    "\n",
    "### Methodological Insights\n",
    "1. **Selection bias is everywhere** in marketing data\n",
    "2. **Naive comparisons** often overestimate effects\n",
    "3. **Causal inference** reveals true business impact\n",
    "4. **ROI calculations** must use causal effects, not correlations\n",
    "5. **Business decisions** improve when based on causal evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison across use cases\n",
    "use_cases_summary = pd.DataFrame({\n",
    "    'Use Case': ['Email Marketing', 'Price Promotions', 'Loyalty Program'],\n",
    "    'Naive Effect': [f'${naive_diff:.0f}', f'{(naive_ratio-1)*100:.1f}%', f'${naive_diff:.0f}'],\n",
    "    'Causal Effect': [f'${email_effect.ate:.0f}', f'{percentage_lift:.1f}%', f'${loyalty_effect.ate:.0f}'],\n",
    "    'True Effect': ['$25', '40%', '$300'],\n",
    "    'Bias Direction': ['Overestimate', 'Underestimate', 'Overestimate'],\n",
    "    'Business Decision': ['Continue', 'Expand', 'Invest']\n",
    "})\n",
    "\n",
    "print(\"=== Marketing Use Cases Summary ===\")\n",
    "print(use_cases_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Key Takeaways ===\")\n",
    "print(\"1. Selection bias affects all marketing interventions\")\n",
    "print(\"2. Causal inference corrects for confounding\")\n",
    "print(\"3. True effects guide optimal resource allocation\")\n",
    "print(\"4. ROI calculations require causal estimates\")\n",
    "print(\"5. Business strategy improves with causal evidence\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}